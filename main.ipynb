{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Until we get real data, make synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporary: Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Data\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(random_state=42)\n",
    "data = np.concatenate((X, y.reshape(-1, 1)), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "np.random.seed(42)\n",
    "states = np.random.randint(low = 0, high = 1000000, size=(100,)) # numpy array with our 100 random states\n",
    "data_splits = {}\n",
    "for rst in states:\n",
    "    data_splits[rst] = preprocess.preprocess(data, rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxep\\OneDrive\\Documents\\Github Repo\\SeniorProject\\TheBioBros\\.conda\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\maxep\\OneDrive\\Documents\\Github Repo\\SeniorProject\\TheBioBros\\.conda\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m model_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mab\u001b[39m\u001b[38;5;124m\"\u001b[39m][state] \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mmodel_adaboost(\u001b[38;5;241m*\u001b[39mdata_splits[state])\n\u001b[0;32m     30\u001b[0m model_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m][state] \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mmodel_logisticregression(\u001b[38;5;241m*\u001b[39mdata_splits[state])\n\u001b[1;32m---> 31\u001b[0m model_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr1\u001b[39m\u001b[38;5;124m\"\u001b[39m][state] \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_lassoregularization\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_splits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m model_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr2\u001b[39m\u001b[38;5;124m\"\u001b[39m][state] \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mmodel_ridgeRegularization(\u001b[38;5;241m*\u001b[39mdata_splits[state])\n\u001b[0;32m     33\u001b[0m model_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlre\u001b[39m\u001b[38;5;124m\"\u001b[39m][state] \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mmodel_elasticNetRegularization(\u001b[38;5;241m*\u001b[39mdata_splits[state])\n",
      "File \u001b[1;32mc:\\Users\\maxep\\OneDrive\\Documents\\Github Repo\\SeniorProject\\TheBioBros\\modeling.py:82\u001b[0m, in \u001b[0;36mmodel_lassoregularization\u001b[1;34m(X_train, X_test, y_train, y_test, state)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodel_lassoregularization\u001b[39m(X_train, X_test, y_train, y_test, state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m):\n\u001b[0;32m     81\u001b[0m     lr1 \u001b[38;5;241m=\u001b[39m LogisticRegression(penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mstate)\n\u001b[1;32m---> 82\u001b[0m     \u001b[43mlr1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m lr1\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, lr1\n",
      "File \u001b[1;32mc:\\Users\\maxep\\OneDrive\\Documents\\Github Repo\\SeniorProject\\TheBioBros\\.conda\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maxep\\OneDrive\\Documents\\Github Repo\\SeniorProject\\TheBioBros\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;124;03m    Fit the model according to the given training data.\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1193\u001b[0m     solver \u001b[38;5;241m=\u001b[39m \u001b[43m_check_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1196\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1197\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_ratio parameter is only used when penalty is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1198\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1199\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(penalty=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty)\n\u001b[0;32m   1200\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\maxep\\OneDrive\\Documents\\Github Repo\\SeniorProject\\TheBioBros\\.conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:63\u001b[0m, in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_solver\u001b[39m(solver, penalty, dual):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m penalty \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 63\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     64\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m supports only \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or None penalties, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpenalty\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpenalty.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m         )\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dual:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m supports only dual=False, got dual=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdual\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "import modeling as models\n",
    "\n",
    "model_res = {} # key as model type, then sub dictionary with rst as key and predicted classes & model itself ex: model_res[\"dt\"][rst] --> (y_pred_dt, dt) \n",
    "model_res[\"dt\"] = {}\n",
    "model_res[\"rf\"] = {}\n",
    "model_res[\"gb\"] = {}\n",
    "model_res['xgb'] = {}\n",
    "model_res[\"lgb\"] = {}\n",
    "model_res[\"et\"] = {}\n",
    "model_res[\"ab\"] = {}\n",
    "model_res[\"lr\"] = {}\n",
    "model_res[\"lr1\"] = {}\n",
    "model_res[\"lr2\"] = {}\n",
    "model_res[\"lre\"] = {}\n",
    "model_res[\"lsv\"] = {}\n",
    "model_res[\"nlsv\"] = {}\n",
    "model_res[\"knn\"] = {}\n",
    "model_res[\"lda\"] = {}\n",
    "model_res[\"gnb\"] = {}\n",
    "model_res[\"mlp\"] = {}\n",
    "\n",
    "for state in data_splits.keys():    \n",
    "    model_res[\"dt\"][state] = models.model_decisiontree(*data_splits[state]) # decision tree\n",
    "    model_res[\"rf\"][state] = models.model_randomforest(*data_splits[state]) # random forest\n",
    "    model_res[\"gb\"][state] = models.model_gradientboosting(*data_splits[state]) # grad boosting\n",
    "    model_res['xgb'][state] = models.model_extremegb(*data_splits[state])\n",
    "    model_res[\"lgb\"][state] = models.model_lightgb(*data_splits[state])\n",
    "    model_res[\"et\"][state] = models.model_extratrees(*data_splits[state])\n",
    "    model_res[\"ab\"][state] = models.model_adaboost(*data_splits[state])\n",
    "    model_res[\"lr\"][state] = models.model_logisticregression(*data_splits[state])\n",
    "    model_res[\"lr1\"][state] = models.model_lassoregularization(*data_splits[state])\n",
    "    model_res[\"lr2\"][state] = models.model_ridgeRegularization(*data_splits[state])\n",
    "    model_res[\"lre\"][state] = models.model_elasticNetRegularization(*data_splits[state])\n",
    "    model_res[\"lsv\"][state] = models.model_linearSupportVector(*data_splits[state])\n",
    "    model_res[\"nlsv\"][state] = models.model_nonLinearSupportVector(*data_splits[state])\n",
    "    model_res[\"knn\"][state] = models.model_kNearestNeighbor(*data_splits[state])\n",
    "    model_res[\"lda\"][state] = models.model_linearDiscriminantAnalysis(*data_splits[state])\n",
    "    model_res[\"gnb\"][state] = models.model_gaussianNaiveBayes(*data_splits[state])\n",
    "    model_res[\"mlp\"][state] = models.model_multiLayerPerceptron(*data_splits[state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for 121958\n",
      "(np.float64(0.9230769230769231), 0.9, 0.7777777777777778, 1.0, 0.875)\n",
      "(np.float64(0.989010989010989), 0.9, 0.7777777777777778, 1.0, 0.875)\n",
      "(np.float64(0.9230769230769231), 0.9, 0.7777777777777778, 1.0, 0.875)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'lg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(getMetrics(data_splits[rst][\u001b[38;5;241m3\u001b[39m], data_splits[rst][\u001b[38;5;241m1\u001b[39m], model_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m][rst][\u001b[38;5;241m0\u001b[39m], model_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m][rst][\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(getMetrics(data_splits[rst][\u001b[38;5;241m3\u001b[39m], data_splits[rst][\u001b[38;5;241m1\u001b[39m], model_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgb\u001b[39m\u001b[38;5;124m\"\u001b[39m][rst][\u001b[38;5;241m0\u001b[39m], model_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgb\u001b[39m\u001b[38;5;124m\"\u001b[39m][rst][\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(getMetrics(data_splits[rst][\u001b[38;5;241m3\u001b[39m], data_splits[rst][\u001b[38;5;241m1\u001b[39m], \u001b[43mmodel_res\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[rst][\u001b[38;5;241m0\u001b[39m], model_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlg\u001b[39m\u001b[38;5;124m\"\u001b[39m][rst][\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lg'"
     ]
    }
   ],
   "source": [
    "# basic view for now to see some metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from metrics import getMetrics\n",
    "for rst in data_splits.keys(): \n",
    "    print(f\"Stats for {rst}\")\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"dt\"][rst][0], model_res[\"dt\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"rf\"][rst][0], model_res[\"rf\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"gb\"][rst][0], model_res[\"gb\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"xgb\"][rst][0], model_res[\"xgb\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"lgb\"][rst][0], model_res[\"lgb\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"et\"][rst][0], model_res[\"et\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"ab\"][rst][0], model_res[\"ab\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"lr\"][rst][0], model_res[\"lr\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"lr1\"][rst][0], model_res[\"lr1\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"lr2\"][rst][0], model_res[\"lr2\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"lre\"][rst][0], model_res[\"lre\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"lsv\"][rst][0], model_res[\"lsv\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"nlsv\"][rst][0], model_res[\"nlsv\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"knn\"][rst][0], model_res[\"knn\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"lda\"][rst][0], model_res[\"lda\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"gnb\"][rst][0], model_res[\"gnb\"][rst][1]))\n",
    "    print(getMetrics(data_splits[rst][3], data_splits[rst][1], model_res[\"mlp\"][rst][0], model_res[\"mlp\"][rst][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
